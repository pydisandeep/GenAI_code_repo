{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5434dcb-0418-4892-8138-1b53691c5ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f39fba7d-5ff9-4baa-b8b8-95f861fdd40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c01c053c-6f5d-4fd6-9642-d979bfc72640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /opt/conda/lib/python3.10/site-packages (4.22.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.110.0)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.13.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.13.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.21.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.5.2)\n",
      "Requirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.15)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.6.4)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from gradio) (6.0)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.3.4)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.10.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.13.0->gradio) (2024.3.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.13.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.11.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.5.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.4)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.3)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.64.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.4)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.36.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.1.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d581ba57-6401-4ec4-9967-1ee9e00f9d60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.10/site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from wordcloud) (1.26.2)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from wordcloud) (10.1.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98117179-c96e-475f-81b0-d0d3fe48aff8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad289df1-a584-4a27-a988-6d60fdc6d073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bc8331d-4d04-4558-ab4b-ef2871a6bdab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.1.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (3.5.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7210489a-5bc7-4e3c-aff9-3278850999ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /opt/conda/lib/python3.10/site-packages (4.22.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.110.0)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.13.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.13.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.21.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.5.2)\n",
      "Requirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.15)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.6.4)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from gradio) (6.0)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.3.4)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.10.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.13.0->gradio) (2024.3.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.13.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.11.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.5.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.4)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.3)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.64.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.4)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.36.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.1.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db831fca-934f-4d51-b21c-4c2d41c01704",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e6d1947-96ee-41a5-853a-98dd461268be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fc2512f-7561-4b15-ada3-a57e9d8af82b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /opt/conda/lib/python3.10/site-packages (0.0.29)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from langchain_community) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community) (2.6.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.9.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2023.11.17)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.10.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_community) (2.16.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3679c66f-9afc-4836-9ea9-ec2fc487751c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms.bedrock import Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f35b8ef9-46ea-4f4a-9bb3-0de1f562a314",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy==2.0.27 in /opt/conda/lib/python3.10/site-packages (2.0.27)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy==2.0.27) (4.10.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy==2.0.27) (1.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SQLAlchemy==2.0.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae71b717-c95c-49a4-98ca-66045c61b097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_modifier = {\n",
    "    \"temperature\": 0.1,\n",
    "    \"p\": 0.9,\n",
    "    \"max_tokens\": 2048\n",
    "}\n",
    "\n",
    "textgen_llm= Bedrock(\n",
    "    model_id=\"cohere.command-text-v14\",\n",
    "    #model_id=\"meta.llama2-13b-chat-v1\",\n",
    "   # model_id='amazon.titan-tg1-large',\n",
    "    #model_id='amazon.titan-text-express-v1',\n",
    "    #model_id='anthropic.claude-v2',\n",
    "    #model_id='anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs=inference_modifier,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3ab0957-3fd2-4973-8a10-13a57a1a9264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_modifier1 = {\n",
    "    \"temperature\": 0.1,\n",
    "    \"p\": 0.9,\n",
    "    \"max_tokens\": 2048\n",
    "}\n",
    "\n",
    "textgen_llm1= Bedrock(\n",
    "    model_id=\"cohere.command-text-v14\",\n",
    "    #model_id=\"meta.llama2-13b-chat-v1\",\n",
    "   # model_id='amazon.titan-tg1-large',\n",
    "    #model_id='amazon.titan-text-express-v1',\n",
    "    #model_id='anthropic.claude-v2',\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs=inference_modifier1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc2dae01-4b20-48f4-81d7-2e8c4940772b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb6cbb46-93a4-4ec8-9947-457a120247b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57b766ce-8ffd-4eee-b48e-6c7a602a9a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template1_newtest =\"\"\"\n",
    "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
    "{context}.\n",
    "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
    "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
    "['Support From Health Care Professionals & Doctors',\n",
    "'Support From Genentech',\n",
    "'Self Service',\n",
    "'Financial Assistance Programs',\n",
    "'Insurance Coverage',\n",
    "'Ease Of Application & Approval',\n",
    "'Cost Related Challenges',\n",
    "'Communication & Customer Support',\n",
    "'No Recommendations / No Concerns']\n",
    "\n",
    "If the theme is not in the list, add the theme to the answer along with other themes.\n",
    "Just give the answer in the following format.\n",
    "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
    "Don't ask any more questions. \n",
    "\n",
    "LIST OF THEMES:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4d2fd56-a10f-4cc1-ba96-948d9985c917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template1_new =\"\"\"\n",
    "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
    "{context}.\n",
    "Assign extracted themes to one of the following themes as given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
    "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
    "['Support From Doctors',\n",
    "'Support From Genentech',\n",
    "'Self Service',\n",
    "'Financial Assistance & Support Programs',\n",
    "'Insurance Coverage',\n",
    "'Ease Of Application & Approval'\n",
    "'Cost Related Challenges'\n",
    "'Communication & Customer Support',\n",
    "'No Recommendations / No Concerns']\n",
    "\n",
    "If the theme is not in the list, add the theme to the answer along with other themes.\n",
    "Just give the answer in the following format.\n",
    "Expected answer format is in a list format like ['Theme-1','Theme-2','Theme-3',..,'Theme-N']\n",
    "Don't ask any more questions. \n",
    "\n",
    "THEMES:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "077b2ba8-faf9-4129-bae7-36156b5dc98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template2_new=\"\"\"You are an expert English linguist. Perform sentiment analysis of the given the text and classify into one of the following: Neutral, Negative, or Positive\n",
    "Text: {context}\n",
    "Expected answer format is python list format like ['sentiment']\n",
    "Sentiment:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f23eeeee-441e-4339-8288-435edfe22924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#eval(\"[hi,2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "111e37d0-c77c-40f0-a763-6a2fd5bec462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#template2_new1=\"\"\"You are an expert English linguist. Perform sentiment analysis on the given tweet and assign one of the \n",
    "#labels = [positive, negative, neutral.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "817be39d-2199-4cbf-a798-16b402cc7209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['context'],\n",
    "    template=template1_newtest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f75baa6-2a88-4e0a-97c3-2ae0a14dac88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['context'],\n",
    "    template=template2_new\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d665b2d-7a9b-4d39-a85e-c3f5112a6703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain1 = LLMChain(\n",
    "    llm=textgen_llm,\n",
    "    prompt=prompt1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b1f9113-e17c-4ac1-87b1-fa158750842d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain2 = LLMChain(\n",
    "    llm=textgen_llm1,\n",
    "    prompt=prompt2,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ea660f2-e3e2-408d-af75-856093551c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5608b364-1e0e-48f3-83dc-a7a0c901cb02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35f3c867-475f-44d9-a992-2bf532272095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_csv(input_csv):\n",
    "    #data=pd.read_csv('test_gradio_new.csv',encoding='latin-1')\n",
    "    data=pd.read_csv(input_csv,encoding='latin-1')\n",
    "    data=data.drop_duplicates().reset_index(drop=True)\n",
    "    data=data.dropna().reset_index(drop=True)\n",
    "    data=pd.DataFrame(data)\n",
    "    def remove_no(x):\n",
    "        return x.lstrip('NnOo'+string.punctuation)\n",
    "    def no_remove(x):\n",
    "        x=x.strip()\n",
    "        if x.lower()[:2]=='no':\n",
    "            return x[2:]\n",
    "        else:\n",
    "            return x\n",
    "    data['Verbatim']=data['Verbatim'].apply(no_remove)\n",
    "    final_list=[]\n",
    "    for index,items in data.iterrows():\n",
    "        i=0\n",
    "        while(True):\n",
    "            if i<20: \n",
    "                o_sentiment=chain2.invoke(items['Verbatim'])\n",
    "                try:\n",
    "                    eval(re.findall(r'\\[.+\\]', o_sentiment['text'])[0])\n",
    "                except:\n",
    "                    i=i+1\n",
    "                    continue\n",
    "                else:\n",
    "                    l1=eval(re.findall(r'\\[.+\\]', o_sentiment['text'])[0])\n",
    "                    l1=list(map(lambda x:x.strip(),l1))\n",
    "                    break\n",
    "            else:\n",
    "                l1=['No Sentiment']\n",
    "                break\n",
    "        if len(items['Verbatim'].split())==1:\n",
    "            l2=['No Recommendations / No Concerns']\n",
    "        else:\n",
    "            j=0\n",
    "            while(True):\n",
    "                if j<20: \n",
    "                    o_theme=chain1.invoke(items['Verbatim'])\n",
    "                    print(o_theme)\n",
    "                    try:\n",
    "                        eval(re.findall(r'\\[.+\\]', o_theme['text'])[0])\n",
    "                    except:\n",
    "                        i=i+1\n",
    "                        continue\n",
    "                    else: \n",
    "                        l2=eval(re.findall(r'\\[.+\\]', o_theme['text'])[0])\n",
    "                        if len(l2)==0:\n",
    "                            l2=['No Recommendations / No Concerns']\n",
    "                            break\n",
    "                        else:\n",
    "                            l2=list(map(lambda x:x.strip(),l2))\n",
    "                            if 'Genentech' in items['Verbatim'] and 'Support From Genentech' not in l2:\n",
    "                                l2.append('Support From Genentech')\n",
    "                            break\n",
    "                else:\n",
    "                    l2=['No Theme']\n",
    "                    break\n",
    "        def f_remove_theme(x):\n",
    "            if x.lower()=='theme':\n",
    "                return x[5:]\n",
    "            else:\n",
    "                return x\n",
    "        l2=list(map(f_remove_theme, l2))\n",
    "        final_list.append(l1+l2)\n",
    "    def f_convert(l):\n",
    "        return [' '.join(list(map(lambda x:x.capitalize(),x.split()))) for x in l]\n",
    "    final_list=list(map(f_convert, final_list))\n",
    "    final_list1=[]\n",
    "    for i in final_list:\n",
    "        final_list1.extend(i)\n",
    "    final_list_new=list(dict.fromkeys(final_list1))\n",
    "    columns=['Positive',\n",
    "         'Neutral',\n",
    "         'Negative','Support From Health Care Professionals & Doctors',\n",
    "        'Support From Genentech',\n",
    "        'Self Service',\n",
    "        'Financial Assistance Programs',\n",
    "        'Insurance Coverage',\n",
    "        'Ease Of Application & Approval',\n",
    "        'Cost Related Challenges',\n",
    "        'Communication & Customer Support',\n",
    "        'No Recommendations / No Concerns']\n",
    "    new_columns=set(final_list_new).difference(set(columns))\n",
    "    columns=columns+list(new_columns)\n",
    "    final_df=pd.DataFrame(columns=columns)\n",
    "    for i in final_list:\n",
    "        temp_list=[]\n",
    "        for j in final_df.columns:\n",
    "            if j in i:\n",
    "                temp_list.append(1)\n",
    "            else:\n",
    "                temp_list.append(0)\n",
    "        temp_df=pd.DataFrame([temp_list], columns=final_df.columns)\n",
    "        final_df=pd.concat([final_df,temp_df],ignore_index=True)\n",
    "    final_df.insert(0,'Verbatim',data)\n",
    "    def generate_bert_embeddings(text):\n",
    "        # Load pre-trained BERT tokenizer and model\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokenized_text = tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "        # Forward pass through BERT model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_text)\n",
    "\n",
    "        # Extract the embeddings from the last hidden state (CLS token)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "        sentence_embedding = torch.mean(embeddings, dim=0)\n",
    "        sentence_embedding = sentence_embedding.numpy()\n",
    "        return sentence_embedding[0]\n",
    "    \n",
    "    def cosine_similarity(vector1, vector2):\n",
    "        dot_product = np.dot(vector1, vector2)\n",
    "        norm_vector1 = np.linalg.norm(vector1)\n",
    "        norm_vector2 = np.linalg.norm(vector2)\n",
    "        similarity = dot_product / (norm_vector1 * norm_vector2)\n",
    "        return similarity\n",
    "    themes_predefined=['Support From Health Care Professionals & Doctors',\n",
    "    'Support From Genentech',\n",
    "    'Self Service',\n",
    "    'Financial Assistance Programs',\n",
    "    'Insurance Coverage',\n",
    "    'Ease Of Application & Approval',\n",
    "    'Cost Related Challenges',\n",
    "    'Communication & Customer Support',\n",
    "    'No Recommendations / No Concerns']\n",
    "    themes_new=list(new_columns)\n",
    "    embed_dict1=dict(zip(themes_predefined, list(map(generate_bert_embeddings, themes_predefined))))\n",
    "    embed_dict2=dict(zip(themes_new, list(map(generate_bert_embeddings, themes_new))))\n",
    "    noise_list=[]\n",
    "    for i in themes_predefined:\n",
    "        temp_list=[]\n",
    "        if len(noise_list)==0:\n",
    "            temp_list.append(i)\n",
    "            for j in themes_new:\n",
    "                if cosine_similarity(embed_dict1[i], embed_dict2[j])>.95:\n",
    "                    temp_list.append(j)\n",
    "            noise_list.append(temp_list)\n",
    "            #print(temp_list)\n",
    "        else:\n",
    "            temp_list.append(i)\n",
    "            for j in themes_new:\n",
    "                if cosine_similarity(embed_dict1[i], embed_dict2[j])>.95:\n",
    "                    temp_list.append(j)\n",
    "            noise_list.append(temp_list)\n",
    "            #print(temp_list)\n",
    "    for i in final_list:\n",
    "        for j in range(1,len(i)):\n",
    "            for k in noise_list:\n",
    "                if i[j] in k[1:]:\n",
    "                    i[j]=k[0]\n",
    "    final_list=list(map(f_convert, final_list))\n",
    "    final_list1=[]\n",
    "    for i in final_list:\n",
    "        final_list1.extend(i)\n",
    "    final_list_new=list(dict.fromkeys(final_list1))\n",
    "    columns=['Positive',\n",
    "     'Neutral',\n",
    "     'Negative','Support From Health Care Professionals & Doctors',\n",
    "    'Support From Genentech',\n",
    "    'Self Service',\n",
    "    'Financial Assistance Programs',\n",
    "    'Insurance Coverage',\n",
    "    'Ease Of Application & Approval',\n",
    "    'Cost Related Challenges',\n",
    "    'Communication & Customer Support',\n",
    "    'No Recommendations / No Concerns']\n",
    "    new_columns=set(final_list_new).difference(set(columns))\n",
    "    columns=columns+list(new_columns)\n",
    "    final_df_new=pd.DataFrame(columns=columns)\n",
    "    for i in final_list:\n",
    "        temp_list=[]\n",
    "        for j in final_df_new.columns:\n",
    "            if j in i:\n",
    "                temp_list.append(1)\n",
    "            else:\n",
    "                temp_list.append(0)\n",
    "        temp_df=pd.DataFrame([temp_list], columns=final_df_new.columns)\n",
    "        final_df_new=pd.concat([final_df_new,temp_df],ignore_index=True)\n",
    "    final_df_new.insert(0,'Verbatim',data)\n",
    "    def f_sum(x):\n",
    "        return sum(x)\n",
    "    final_df_new1=final_df_new.iloc[:,1:]\n",
    "    final_df_sentiment=final_df_new1.iloc[:,:3]\n",
    "    final_df_themes=final_df_new1.iloc[:,3:]\n",
    "    sentiment_dict={}\n",
    "    theme_dict={}\n",
    "    for i in final_df_sentiment:\n",
    "        sentiment_dict[i]=f_sum(final_df_sentiment[i].to_list())\n",
    "    for i in final_df_themes:\n",
    "        theme_dict[i]=f_sum(final_df_themes[i].to_list())\n",
    "    def pie_chart(sentiment_dict):\n",
    "        # Extracting item names and counts\n",
    "        items = list(sentiment_dict.keys())\n",
    "        counts = list(sentiment_dict.values())\n",
    "        colors = ['#00FF00', '#FFFF00','#FF0000']\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.pie(counts, labels=items, autopct='%1.1f%%',colors=colors, startangle=140)\n",
    "        plt.title('Sentiment Distribution')\n",
    "        plt.axis('equal')\n",
    "        pie_chart='/root/CIA/pie.png'\n",
    "        plt.savefig(pie_chart)\n",
    "        plt.close()\n",
    "        return pie_chart\n",
    "    def wordcloud(theme_dict):\n",
    "        from wordcloud import WordCloud\n",
    "        # Generating word cloud\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(theme_dict)\n",
    "        # Plotting the word cloud\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        wordcloud='/root/CIA/wordcloud.png'\n",
    "        plt.savefig(wordcloud)\n",
    "        plt.close()\n",
    "        return wordcloud\n",
    "    output_csv_filename = \"VoC.csv\"\n",
    "    final_df_new.to_csv(output_csv_filename, index=False)\n",
    "    return output_csv_filename, pie_chart(sentiment_dict), wordcloud(theme_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e9b4c15-5f76-4b9f-8c8e-b511e9a05df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://e3be9e58c4ed4485f3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e3be9e58c4ed4485f3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an expert English linguist. Perform sentiment analysis of the given the text and classify into one of the following: Neutral, Negative, or Positive\n",
      "Text: Searching for info was fun.\n",
      "Expected answer format is python list format like ['sentiment']\n",
      "Sentiment:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "Searching for info was fun..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'Searching for info was fun.', 'text': ' \\nI have analyzed the text and identified the following themes: \\n- Communication and Customer Support \\n- Search and Information Retrieval \\n- User Experience and Satisfaction \\n- Information Seeking Behavior \\n\\nThese themes represent the key ideas and topics mentioned in the text. \\n\\nWould you like me to further elaborate on any of these themes? \\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "Searching for info was fun..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'Searching for info was fun.', 'text': ' \\nI have analyzed the text and identified the following themes: \\n- Communication and Customer Support \\n- Searching for Information \\n- Support from Doctors and Health Care Professionals \\n\\nThese themes represent the key ideas from the text. \\n\\nWould you like me to further elaborate on these themes? \\nOr would you like me to extract more themes from the text? \\n\\nI can also provide additional themes that are not included in the list above if you would like. '}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "Searching for info was fun..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'Searching for info was fun.', 'text': ' \\nI have analyzed the text and identified the following themes: \\n- Communication and Customer Support \\n- Searching for Information \\n- Support from Health Care Professionals \\n\\nThese themes represent the key topics mentioned in the provided text. \\n\\nWould you like me to further elaborate on these themes? \\nOr would you like me to extract more themes from the text?\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "Searching for info was fun..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'Searching for info was fun.', 'text': ' \\nI have analyzed the text and extracted the following themes from the given text: \\n- Communication and Customer Support \\n- Search and Information Retrieval \\n- User Experience and Feedback\\n\\nWould you like me to assign the extracted themes to the predefined themes in the list? '}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "Searching for info was fun..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'Searching for info was fun.', 'text': ' \\nI have analyzed the text and extracted the following themes from the given text: \\n- Communication and Customer Support \\n- Search and Information Retrieval \\n- User Experience and Satisfaction \\n\\nThese themes are not included in the list of predefined themes, so I have added them to the list below: \\nSupport From Health Care Professionals & Doctors\\nSupport From Genentech\\nSelf Service\\nFinancial Assistance Programs\\nInsurance Coverage\\nEase of Application and Approval \\nCost Related Challenges \\nCommunication and Customer Support\\nSearch and Information Retrieval\\nUser Experience and Satisfaction \\n\\nI hope this helps! '}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "Searching for info was fun..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'Searching for info was fun.', 'text': \" \\nI have analyzed the text and identified the following themes: \\n['Support From Health Care Professionals', 'Information Search'] \\n\\nThese themes were not in your list, so I have added them as individual items in the list. \\n\\nWould you like me to ask any further questions?\\n\"}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an expert English linguist. Perform sentiment analysis of the given the text and classify into one of the following: Neutral, Negative, or Positive\n",
      "Text: I spoke one rep who totally confused me but i then called again and got cleared information.  Training in how to speak to patients is very important.\n",
      "Expected answer format is python list format like ['sentiment']\n",
      "Sentiment:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "I spoke one rep who totally confused me but i then called again and got cleared information.  Training in how to speak to patients is very important..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'I spoke one rep who totally confused me but i then called again and got cleared information.  Training in how to speak to patients is very important.', 'text': ' \\nThe text can be assigned to the following themes: \\n- Communication & Customer Support \\n- Support From Health Care Professionals & Doctors\\n\\nAlthough there are other themes present in the text, the two most prominent ones are **Communication & Customer Support**, and **Support From Health Care Professionals & Doctors**. \\n\\nWould you like me to explain how I arrived at this answer?\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "I spoke one rep who totally confused me but i then called again and got cleared information.  Training in how to speak to patients is very important..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'I spoke one rep who totally confused me but i then called again and got cleared information.  Training in how to speak to patients is very important.', 'text': ' \\nThe following are the most relevant themes from the text you provided, extracted and organized in a list:\\n\\n- Communication and Customer Support \\n- Training \\n- Support from Health Care Professionals and Doctors \\n\\nThe text you provided does not mention the other themes you listed, so they have not been included in the answer. \\nIs there anything else I can help you with?\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "I spoke one rep who totally confused me but i then called again and got cleared information.  Training in how to speak to patients is very important..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'I spoke one rep who totally confused me but i then called again and got cleared information.  Training in how to speak to patients is very important.', 'text': ' \\nThe following are the most relevant themes from the text you provided, extracted and organized in a list:\\n- Communication and Customer Support \\n- Training \\n- Support from Health Care Professionals and Doctors \\n\\nThe themes that were not identified as being relevant are not included in the list. Please let me know if you would like me to elaborate on any of the themes or if you would like me to extract any other information from the text. '}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "I spoke one rep who totally confused me but i then called again and got cleared information.  Training in how to speak to patients is very important..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'I spoke one rep who totally confused me but i then called again and got cleared information.  Training in how to speak to patients is very important.', 'text': \" \\nThe following are the most relevant themes from the text you provided, extracted and assigned to the given list of themes:\\n\\n['Communication & Customer Support', 'Support From Health Care Professionals & Doctors']\\n\\nThe text discusses the need for training in communication with patients, which falls under the theme of 'Communication & Customer Support'. The text also refers to a conversation with a healthcare professional, highlighting the importance of support from healthcare professionals and doctors. \\n\\nHowever, I have also added the theme 'Support From Health Care Professionals & Doctors' to the list as it wasn't present in the original list of themes.\\n\\nWould you like me to process more text for theme extraction?\\n\"}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an expert English linguist. Perform sentiment analysis of the given the text and classify into one of the following: Neutral, Negative, or Positive\n",
      "Text: Didnt know what the cost would be - I would like to have known, but I need the product\n",
      "Expected answer format is python list format like ['sentiment']\n",
      "Sentiment:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "Didnt know what the cost would be - I would like to have known, but I need the product.\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'Didn\\x92t know what the cost would be - I would like to have known, but I need the product', 'text': \" \\nThe following are the most relevant themes from the given text, extracted and assigned based on the predefined themes you have provided:\\n\\n['Cost Related Challenges', 'Insurance Coverage']\\n\\nThe text mentions the desire to know the cost of a product, which is categorized under *Cost Related Challenges*. Additionally, the text also alludes to the need for insurance coverage, which is separately categorized under *Insurance Coverage*. \\n\\nIs there anything else you would like assistance with?\\n\"}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an expert English linguist. Perform sentiment analysis of the given the text and classify into one of the following: Neutral, Negative, or Positive\n",
      "Text: , the financial aid support is very grateful.\n",
      "Expected answer format is python list format like ['sentiment']\n",
      "Sentiment:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      ", the financial aid support is very grateful..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': ', the financial aid support is very grateful.', 'text': ' \\nThe text provided is related to the following themes: \\n- Financial Assistance Programs \\n- Support From Health Care Professionals & Doctors \\n- Communication and Customer Support \\n\\nWould you like to know more about any of these themes? \\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      ", the financial aid support is very grateful..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': ', the financial aid support is very grateful.', 'text': ' \\nThe text provided is related to the following themes: \\n- Financial Assistance Programs \\n- Support From Health Care Professionals & Doctors \\n- Communication and Customer Support \\n\\nWould you like me to explain how I arrived at the above themes? \\nOr would you like me to extract the themes from another text? \\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      ", the financial aid support is very grateful..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': ', the financial aid support is very grateful.', 'text': ' \\nThe text provided is related to the following themes: \\n- Financial Assistance Programs \\n- Support From Health Care Professionals & Doctors \\n- Communication and Customer Support \\n\\nWould you like to know more about any of these themes?\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      ", the financial aid support is very grateful..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': ', the financial aid support is very grateful.', 'text': ' \\nThe text provided is related to the following themes: \\n- Financial Assistance Support\\n- Communication and Customer Support \\n- Cost Related Challenges \\n\\nIs there anything else I can help you with?\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      ", the financial aid support is very grateful..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': ', the financial aid support is very grateful.', 'text': ' \\nThe text provided expresses gratitude for the support received from the financial aid program, and I would like to extract the following themes from the text: \\n1.  Financial Assistance Programs \\n2.  Support From Financial Aid\\n\\nIf there are any other themes that you would like me to identify from the text, please let me know. \\nI am always happy to help.\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      ", the financial aid support is very grateful..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': ', the financial aid support is very grateful.', 'text': \" \\nThe text provided is related to the following themes: \\n['Financial Assistance Programs', 'Support From Genentech', 'Communication and Customer Support', 'Cost-related challenges'] \\n\\nI added the themes 'Communication and Customer Support' and 'Cost-related challenges' as they are the most relevant to the text. \\n\\nIs there anything else I can help you with?\\n\"}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an expert English linguist. Perform sentiment analysis of the given the text and classify into one of the following: Neutral, Negative, or Positive\n",
      "Text: If they would have told me upfront how much the cost would be. I was relieved after the fact that they got the price reduced.\n",
      "Expected answer format is python list format like ['sentiment']\n",
      "Sentiment:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "If they would have told me upfront how much the cost would be. I was relieved after the fact that they got the price reduced..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'If they would have told me upfront how much the cost would be. I was relieved after the fact that they got the price reduced.', 'text': ' \\nThe following are the most relevant themes from the text provided, extracted and assigned to the closest matching themes from the list you gave me. \\n\\n- **Cost Related Challenges**\\n- **Communication and Customer Support** \\n\\nSince there were no other themes that matched the provided text, I have added these two themes to the answer, along with the one that was matched. \\n\\nWould you like me to extract more themes from the text? '}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "If they would have told me upfront how much the cost would be. I was relieved after the fact that they got the price reduced..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'If they would have told me upfront how much the cost would be. I was relieved after the fact that they got the price reduced.', 'text': ' \\nThe following are the most relevant themes from the text provided, extracted and assigned to the given themes:\\n- Cost Related Challenges\\n- Communication and Customer Support \\n- \\tInsurance Coverage\\n\\nSince no other themes were mentioned in the text, there are no other relevant themes to extract. \\n\\nWould you like to know more about any of these themes?\\n'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert in understanding a given text. Extract the most relevant themes from the following:\n",
      "If they would have told me upfront how much the cost would be. I was relieved after the fact that they got the price reduced..\n",
      "Assign extracted themes to one of the following themes in tthe list given below by taking text similarity and give that as answer in a list. If the theme doesn't\n",
      "belong to any of the given pre-defined themes, add the theme to the answer along with other themes. Below is the list of themes:\n",
      "['Support From Health Care Professionals & Doctors',\n",
      "'Support From Genentech',\n",
      "'Self Service',\n",
      "'Financial Assistance Programs',\n",
      "'Insurance Coverage',\n",
      "'Ease Of Application & Approval',\n",
      "'Cost Related Challenges',\n",
      "'Communication & Customer Support',\n",
      "'No Recommendations / No Concerns']\n",
      "\n",
      "If the theme is not in the list, add the theme to the answer along with other themes.\n",
      "Just give the answer in the following format.\n",
      "Expected answer format is ['Theme1','Theme2','Theme3',..,'ThemeN']\n",
      "Don't ask any more questions. \n",
      "\n",
      "LIST OF THEMES:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'context': 'If they would have told me upfront how much the cost would be. I was relieved after the fact that they got the price reduced.', 'text': ' \\nThe following are the most relevant themes from the text provided, extracted and assigned to the given themes:\\n\\n[\\'Cost Related Challenges\\', \\'Communication & Customer Support\\']\\n\\nIf required, here is the text for reference:\\n\\n\"If they had told me from the beginning about the actual costs, I would have been more relieved. In the end, I was relieved they got the price reduced for me.\" \\n\\nThe speaker is primarily concerned with the cost of the service and how it was communicated (or not) to them, which could be improved going forward. \\n\\nIs there anything else I can help you extract from this text? '}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "demo = gr.Interface(\n",
    "        fn=process_csv,\n",
    "        inputs=[\"file\"],\n",
    "        outputs=[\"file\",\"image\",\"image\"])\n",
    "\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c7ee3-f94e-4f5d-a337-51bb9f193b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7800e1a4-670d-48e4-88fd-0ce7f2420d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f912cb0-ad57-4a76-a6a5-5f350bb0394a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e73b5-7c1f-43ff-9026-5cf79be399f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
